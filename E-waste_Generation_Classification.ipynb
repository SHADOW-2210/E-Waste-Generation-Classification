{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d56b201f",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sklearn'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 17\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m  \u001b[38;5;66;03m# Plotting graphs and images\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mseaborn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01msns\u001b[39;00m  \u001b[38;5;66;03m# Plotting graphs and images\u001b[39;00m\n\u001b[1;32m---> 17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m confusion_matrix, classification_report  \u001b[38;5;66;03m# Evaluation metrics for classification models\u001b[39;00m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mgradio\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mgr\u001b[39;00m  \u001b[38;5;66;03m# Web interface library to deploy and test ML models\u001b[39;00m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mPIL\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Image  \u001b[38;5;66;03m# For image file loading and basic image operations\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'sklearn'"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf  # Core TensorFlow library\n",
    "\n",
    "from tensorflow.keras import layers, models, optimizers, callbacks  # Layers, model creation, optimizers, and training callbacks\n",
    "\n",
    "from tensorflow.keras.models import Sequential, load_model  # For sequential model architecture and loading saved models\n",
    "\n",
    "from tensorflow.keras.applications import EfficientNetV2B0  # Pretrained EfficientNetV2B0 model for transfer learning\n",
    "\n",
    "from tensorflow.keras.applications.efficientnet import preprocess_input  # Preprocessing function specific to EfficientNet\n",
    "\n",
    "import numpy as np  # Numerical operations and array handling\n",
    "\n",
    "import matplotlib.pyplot as plt  # Plotting graphs and images\n",
    "\n",
    "import seaborn as sns  # Plotting graphs and images\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, classification_report  # Evaluation metrics for classification models\n",
    "\n",
    "import gradio as gr  # Web interface library to deploy and test ML models\n",
    "\n",
    "from PIL import Image  # For image file loading and basic image operations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07490158",
   "metadata": {},
   "outputs": [],
   "source": [
    "testpath= r'C:\\Users\\Edunet Foundation\\Downloads\\project\\E waste data\\modified-dataset\\test'\n",
    "trainpath= r'C:\\Users\\Edunet Foundation\\Downloads\\project\\E waste data\\modified-dataset\\train'\n",
    "validpath = r'C:\\Users\\Edunet Foundation\\Downloads\\project\\E waste data\\modified-dataset\\val'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0981e757",
   "metadata": {},
   "outputs": [],
   "source": [
    "datatrain= tf.keras.utils.image_dataset_from_directory(trainpath,shuffle = True, image_size = (128,128), batch_size = 32, validation_split= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a59d555",
   "metadata": {},
   "outputs": [],
   "source": [
    "datatest=tf.keras.utils.image_dataset_from_directory(testpath,shuffle = False, image_size = (128,128), batch_size = 32, validation_split= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "460187d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "datavalid = tf.keras.utils.image_dataset_from_directory(validpath,shuffle = True, image_size = (128,128), batch_size = 32, validation_split= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eba2c1f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(datatrain.class_names))\n",
    "class_names = datatrain.class_names\n",
    "print(class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3bd2d99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the size of the entire figure (width=10, height=10 inches)\n",
    "plt.figure(figsize=(10, 10))\n",
    "\n",
    "# Take one batch from the dataset and iterate over the images and labels\n",
    "for images, labels in datatrain.take(1):\n",
    "    # Display the first 12 images from the batch\n",
    "    for i in range(12):\n",
    "        # Create a 4x3 grid of subplots and select the (i+1)th position\n",
    "        ax = plt.subplot(4, 3, i + 1)\n",
    "\n",
    "        # Display the image; convert the tensor to a NumPy array and ensure correct type\n",
    "        plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
    "\n",
    "        # Set the title of the subplot to the class name of the image\n",
    "        plt.title(class_names[labels[i]])\n",
    "\n",
    "        # Remove axis ticks and labels for clarity\n",
    "        plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95e23054",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_class_distribution(dataset, title=\"Class Distribution\"):\n",
    "    \"\"\"\n",
    "    Plots the number of items per class in a given dataset.\n",
    "\n",
    "    Args:\n",
    "        dataset: A tf.data.Dataset object created using image_dataset_from_directory\n",
    "        title: Title for the plot (e.g., 'Train Data Distribution')\n",
    "    \"\"\"\n",
    "\n",
    "    class_counts = {}  # Dictionary to hold the count of each class\n",
    "\n",
    "    # Iterate through the batches in the dataset\n",
    "    for images, labels in dataset:\n",
    "        # Convert labels tensor to numpy array and loop through each label\n",
    "        for label in labels.numpy():\n",
    "            class_name = dataset.class_names[label]  # Get class name using label index\n",
    "            # Increment the count for this class\n",
    "            class_counts[class_name] = class_counts.get(class_name, 0) + 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60920cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    # Prepare data for plotting\n",
    "    class_names = list(class_counts.keys())  # List of class names\n",
    "    counts = list(class_counts.values())     # Corresponding counts for each class\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a0e6b28",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    # Create the bar plot\n",
    "    plt.figure(figsize=(10, 6))  # Set the figure size\n",
    "    plt.bar(class_names, counts, color='skyblue')  # Draw bars with class counts\n",
    "    plt.xlabel(\"Class\")  # X-axis label\n",
    "    plt.ylabel(\"Number of Items\")  # Y-axis label\n",
    "    plt.title(title)  # Plot title\n",
    "    plt.xticks(rotation=45)  # Rotate x-axis labels for better readability\n",
    "    plt.tight_layout()  # Adjust layout to prevent clipping\n",
    "    plt.show()  # Display the plot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bfd0ce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_class_distribution(datatrain, \"Training Data Distribution\")\n",
    "plot_class_distribution(datavalid, \"Validation Data Distribution\")\n",
    "plot_class_distribution(datatest, \"Test Data Distribution\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f4eb30c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data_augmentation = tf.keras.Sequential([\n",
    "    tf.keras.layers.RandomFlip(\"horizontal\"),\n",
    "    tf.keras.layers.RandomRotation(0.1),\n",
    "    tf.keras.layers.RandomZoom(0.1),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48827f2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = tf.keras.applications.EfficientNetV2B0(\n",
    "    input_shape=(128, 128, 3),\n",
    "    include_top=False,\n",
    "    weights='imagenet'\n",
    ")\n",
    "base_model.trainable = True\n",
    "for layer in base_model.layers[:100]:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e3fc747",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Input(shape=(128, 128, 3)),\n",
    "    data_augmentation,\n",
    "    base_model,\n",
    "    tf.keras.layers.GlobalAveragePooling2D(),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),loss = tf.keras.losses.SparseCategoricalCrossentropy(), metrics=['Accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "828c3428",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define an EarlyStopping callback to stop training when validation loss stops improving\n",
    "early = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss',            # Metric to monitor (validation loss here)\n",
    "    patience=3,                   # Number of epochs to wait after last improvement before stopping\n",
    "    restore_best_weights=True     # After stopping, restore the model weights from the epoch with the best val_loss\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beb5280b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the number of epochs to train the model\n",
    "epochs = 15\n",
    "\n",
    "# Train the model on the training dataset 'datatrain'\n",
    "history = model.fit(\n",
    "    datatrain,                      # Training data generator or dataset\n",
    "    validation_data=datavalid,      # Validation data generator or dataset\n",
    "    epochs=epochs,                  # Number of training epochs\n",
    "    batch_size=100,                 # Number of samples per gradient update\n",
    "    callbacks=[early]               # List of callbacks to apply during training (e.g., early stopping)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a86a9db4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary() # Print the architecture summary of the  model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdda3904",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model.summary() # Print the architecture summary of the base model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b5e673b",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Plotting Training and Validation Accuracy and Loss Over Epochs\n",
    "\n",
    "acc = history.history['Accuracy']           # Training accuracy\n",
    "val_acc = history.history['val_Accuracy']   # Validation accuracy\n",
    "loss = history.history['loss']              # Training loss\n",
    "val_loss = history.history['val_loss']      # Validation loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "035c199b",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs_range = range(len(acc))              # X-axis range based on number of epochs\n",
    "\n",
    "plt.figure(figsize=(10, 8))                 # Set overall figure size\n",
    "\n",
    "plt.subplot(1, 2, 1)                        # 1 row, 2 columns, position 1\n",
    "plt.plot(epochs_range, acc, label='Training Accuracy')       # Plot training accuracy\n",
    "plt.plot(epochs_range, val_acc, label='Validation Accuracy') # Plot validation accuracy\n",
    "plt.legend(loc='lower right')              # Show legend at lower right\n",
    "plt.title('Training vs Validation Accuracy') # Set title for accuracy plot\n",
    "\n",
    "plt.subplot(1, 2, 2)                        # 1 row, 2 columns, position 2\n",
    "plt.plot(epochs_range, loss, label='Training Loss')          # Plot training loss\n",
    "plt.plot(epochs_range, val_loss, label='Validation Loss')    # Plot validation loss\n",
    "plt.legend(loc='upper right')              # Show legend at upper right\n",
    "plt.title('Training vs Validation Loss')    # Set title for loss plot\n",
    "\n",
    "plt.show()                                  # Display the plots\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2756527f",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, accuracy = model.evaluate(datatest)\n",
    "print(f'Test accuracy is{accuracy:.4f}, Test loss is {loss:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df056a68",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Evaluate Model Performance on Test Data using Confusion Matrix and Classification Report\n",
    "\n",
    "# Extract true labels from all batches\n",
    "y_true = np.concatenate([y.numpy() for x, y in datatest], axis=0)  # Ground truth labels\n",
    "\n",
    "# Get predictions as probabilities and then predicted classes\n",
    "y_pred_probs = model.predict(datatest)\n",
    "\n",
    "# Class with highest probability\n",
    "y_pred = np.argmax(y_pred_probs, axis=1)                           \n",
    "\n",
    "# Print confusion matrix and classification report\n",
    "print(confusion_matrix(y_true, y_pred))                            \n",
    "print(classification_report(y_true, y_pred))                     \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66d9bda2",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Plot Confusion Matrix as Heatmap for Better Visualization\n",
    "\n",
    "cm = confusion_matrix(y_true, y_pred)                                     # Compute confusion matrix\n",
    "                                                     # Import seaborn for visualization\n",
    "\n",
    "plt.figure(figsize=(10, 8))                                               # Set figure size\n",
    "sns.heatmap(cm, annot=True, fmt='d', \n",
    "            xticklabels=class_names, \n",
    "            yticklabels=class_names, \n",
    "            cmap='Blues')                                                 # Create heatmap with class labels\n",
    "\n",
    "plt.xlabel('Predicted')                                                   # Label for x-axis\n",
    "plt.ylabel('True')                                                        # Label for y-axis\n",
    "plt.title('Confusion Matrix')                                             # Title for the plot\n",
    "plt.show()                                                                # Display the plot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afbaa1d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Display Sample Predictions: True Labels vs Predicted Labels\n",
    "\n",
    "class_names = datatest.class_names                                           # Get class names from test dataset\n",
    "\n",
    "for images, labels in datatest.take(1):                                     # Take one batch from test data\n",
    "    predictions = model.predict(images)                                     # Predict class probabilities\n",
    "    pred_labels = tf.argmax(predictions, axis=1)                            # Get predicted class indices\n",
    "\n",
    "    for i in range(8):                                                      # Display first 8 images from batch\n",
    "        plt.imshow(images[i].numpy().astype(\"uint8\"))                       # Convert tensor to image\n",
    "        plt.title(f\"True: {class_names[labels[i]]}, Pred: {class_names[pred_labels[i]]}\")  # Title with labels\n",
    "        plt.axis(\"off\")                                                     # Hide axes\n",
    "        plt.show()                                                          # Show image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6ee2514",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model in Keras format with architecture, weights, and training configuration\n",
    "model.save('Efficient_classify.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e350b1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your class labels\n",
    "class_names = ['Battery', 'Keyboard', 'Microwave', 'Mobile', 'Mouse', 'PCB', 'Player', 'Printer', 'Television', 'Washing Machine']\n",
    "\n",
    "# Load your Keras model\n",
    "model = tf.keras.models.load_model('Efficient_classify.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72ae19cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install gradio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7abae089",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_image(img):\n",
    "    # Step 1: Resize and convert to array\n",
    "    img = img.resize((128, 128))\n",
    "    img_array = np.array(img, dtype=np.float32)\n",
    "\n",
    "    # Step 2: Preprocess and add batch dimension\n",
    "    img_array = preprocess_input(img_array)\n",
    "    img_array = np.expand_dims(img_array, axis=0)\n",
    "\n",
    "    # Step 3: Predict using the model\n",
    "    prediction = model.predict(img_array)\n",
    "    index = np.argmax(prediction)  # Get index of highest score\n",
    "\n",
    "    # Step 4: Get class name and confidence\n",
    "    class_name = class_names[index]\n",
    "    confidence = prediction[0][index]\n",
    "\n",
    "    return f\"Predicted: {class_name} (Confidence: {confidence:.2f})\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "767894f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Gradio interface for the classify_image function\n",
    "iface = gr.Interface(\n",
    "    fn=classify_image,          # The function to run when input is given\n",
    "    inputs=gr.Image(type=\"pil\"), # Input component: expects an image as a PIL object\n",
    "    outputs=\"text\"              # Output component: displays the result as plain text\n",
    ")\n",
    "\n",
    "# Launch the Gradio interface, opening a local web app to interact with the model\n",
    "iface.launch()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
